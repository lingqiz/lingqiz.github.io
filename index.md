---
layout: page
name: index
title: Personal Website
description: >
  Personal Website of Ling-Qi Zhang, PhD Candidate in Computational Neuroscience at Penn.
hide_description: true
---
<!-- <script type="text/javascript">
	document.getElementsByClassName("page-title")[0].classList.add("sr-only");
</script> -->

<style type="text/css">
	.page-title {
		position: absolute;
		width: 1px;
  		height: 1px;
  		margin: -1px;
  		border: 0;
  		padding: 0;
  		clip: rect(0 0 0 0);
  		overflow: hidden;
	}
</style>

<h2 class="h1" style="color: rgb(1,92,171)" id="about">About Me </h2>

Hi there! My name is Ling-Qi. I am a 4th year PhD student at the University of Pennsylvania working with [David Brainard](https://color.psych.upenn.edu/) and [Alan Stocker](https://www.sas.upenn.edu/~astocker/lab/index.php) in the [Department of Psychology](https://psychology.sas.upenn.edu) and the [Computational Neuroscience Initiative](http://cni.upenn.edu/). 

Previously, I did my undergraduate in Computer Science, at [Southern University of Science and Technology](https://www.sustech.edu.cn/en/) which is newly established in 2011 at Shenzhen, China. ([Short story about our university](http://www.nature.com/news/chinese-university-wins-degree-of-freedom-1.10631))

I am interested in how the brain works from a computational perspective. Right now, my research focuses on how regularities in the generative structure of our visual world shape our sensory system. This consists of mainly two aspects:

1) Efficient coding, which studies how the brain should optimize its representation to maximize the amount of information transmission, often under realistic biological constraint; And 2) Bayesian inference, which studies if and what prior regularities the brain makes use of to solve ambiguous inference problem.

Going forward, I am particularly interested in studying these questions in the context of complex, naturalistic tasks, to understand the extent to which our brain is indeed "optimal" and its limitations when facing challenging inference problem.

---
<h2 class="h1" style="color: rgb(1,92,171)" id="research">Research </h2>
<h3 class="h2">Current Projects</h3>

**BEHAVIORAL AND NEURAL EFFICIENT CODING OF SPEED**  
*[\[V-VSS 2021 Poster\]]()  [\[Data+Code\]](https://github.com/lingqiz/EfficientCoding)* <br>

<div class="row">
  <div class="column">
  <img src="/assets/img/speedPrior.png" style="width:400px;height:290px;">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of speed stimuli, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<br>
**BAYESIAN IMAGE RECONSTRUCTION FROM CONE MOSAIC SIGNAL**  
*[\[V-VSS 2020 Talk\]](https://youtu.be/d5qI0FNCAv4)  [\[Github\]](https://github.com/isetbio/ISETImagePipeline)* <br>

<div class="row">
  <div class="column">
  <img src="/assets/img/imageRecon.png" style="width:400px;height:370px;">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of speed stimuli, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<br>
**ABERRANT VISUAL ORIENTATION ENCODING IN INDIVIDUALS WITH AUTISM**  
*[\[bioRxiv\]](https://www.biorxiv.org/content/10.1101/2020.03.04.976191v1.abstract)  [\[Data+Code\]](https://github.com/lingqiz/ASD_Encoding_2020)* <br>

<div class="row">
  <div class="column">
  <img src="/assets/img/encodingASD.png" style="width:400px;height:273;">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of speed stimuli, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<h3 class="h2">Selected Past Projects</h3>

**PSYCHOPHYSICS WITH DEEP NEURAL NETWORKS**  
*[\[CCN 2019\]](https://ccneuro.org/2019/proceedings/0000585.pdf)* <br>

<div class="row">
  <div class="column">
  <img src="/assets/img/ccn2019.png" style="width:400px;height:318px;">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of speed stimuli, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<br>
**COURSE PROJECT (CSE 167/168X, COMPUTER GRAPHICS)**  
*[\[Simple Python Ray Tracer\]](https://github.com/lingqiz/CSE-167x-RayTracer)  [\[Path Tracer with OptiX\]](https://github.com/lingqiz/CSE-168x-OptiX)* <br>

<div class="row">
  <div class="column">
  <img src="/assets/img/cse167.png" style="width:400px;height:264px;">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of speed stimuli, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<br>

---
<h2 class="h1" style="color: rgb(1,92,171)" id="publications">Publications </h2>

<h3 class="h2">Peer-reviewed Conference Papers</h3>

* **Abir Saha** and Anne Marie Piper. [Understanding Audio Production Practices of People with Vision Impairments](https://abirsh.github.io/publications/BVI-audio-ASSETS2020-preprint.pdf){:target="_blank"}. In *Proceedings of the 22nd International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2020)*, Virtual Event, Greece, October 2020.   
<span class="icon-award" aria-hidden="true"></span> **Best Paper Nominee**   
  

* Lin Li, **Abir Saha**, Seeta Ram Pandey, Yaobin Chen, Stanley Chien, and Rini Sherony. Infrared Reflectance Requirements of Metal Guardrail Surrogates for the Evaluation of Vehicle Road Departure Mitigation Systems. In *2019 IEEE Intelligent Transportation Systems Conference (ITSC)*, Auckland, New Zealand, October 2019. [[IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/8917344){:target="_blank"}]   
  

* Moushumi Sharmin, Monsur Hossain, **Abir Saha**, Maitraye Das, Margot Maxwell, and Shameem Ahmed. [From Research to Practice: Informing the Design of Autism Support Smart Technology](https://abirsh.github.io/publications/Autism_CHI18.pdf){:target="_blank"}. In *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 2018)*, Montreal, Canada, April 2018. [[ACM DL](https://dl.acm.org/doi/abs/10.1145/3173574.3173676){:target="_blank"}]   
  

* **Abir Saha** and Maitraye Das. Impact of Social Networking on Post-Partum Depression in Women: An Analysis in the Context of Bangladesh. In *Proceedings of the 20th IEEE International Conference on Computer and Information Technology (ICCIT)*, Dhaka, Bangladesh, December 2017. [[IEEE Xplore](https://doi.org/10.1109/ICCITECHN.2017.8281831){:target="_blank"}]   

---
<h2 class="h1" style="color: rgb(1,92,171)" id="contact-me">Contact Me </h2>

Department of Psychology  
Stephen A. Levin Building   
425 S. University Ave   
Philadelphia, PA 19104   

<p class="home-element"><strong>lingqiz [at] sas [dot] upenn [dot] edu</strong></p>

<style type="text/css">
  .body-social > ul {
    display: inline-block;
    list-style-type: none;
    margin-bottom: 0;
    overflow: hidden;
    padding: 0;
  }

  .body-social > ul > li {
    float: left;
    
    /* padding-left: 5px; */
    padding-right: 10px;
    
    /* display: inline-block; */
  }

  .body-social > ul > li > a {
    display: inline;
    text-align: center;
    font-size: 0.95rem;
    font-weight: 600;
    /*width: 3rem;*/
    /*height: 4rem;*/
    padding: 4px;
    
    /* line-height: 3rem; */
    
    text-decoration: none;
    border-width: 1px;
    border-style: solid;
    border-radius: 5px;
    transition: background-color 250ms, color 250ms, text-decoration-color 250ms, border-color 250ms;
    
    /* border-bottom: none; */
  }

  .body-social > ul > li > a:not(.btn):not(.no-hover) {
    border-color: var(--accent-color);
  }

  .body-social > ul > li > a:hover {
    color: white;
    background-color: var(--accent-color);
    border-radius: 5px;
    padding: 4px;
    transition: background-color 250ms, color 250ms, text-decoration-color 250ms, border-color 250ms;
  }

  .row {
    display: flex;
  }

  .column {
    flex: 50%;    
  }
</style>